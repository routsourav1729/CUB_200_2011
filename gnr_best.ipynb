{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOINNSu8wai5BgCdeMYJ3AO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/routsourav1729/CUB_200_2011/blob/main/gnr_best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAQf6Pw8qfbI",
        "outputId": "26054459-cf26-4ff4-e4e9-91e61c8295dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CUB_200_2011' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/routsourav1729/CUB_200_2011.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLsNDwArqkoZ",
        "outputId": "137977e9-9b7a-48e2-bab8-decd8d10b7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet-pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=0f3659657a45bf87c30d47f874463d2101926efda7430233de20969161a2dee3\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"torchvision>0.16.0\""
      ],
      "metadata": {
        "id": "EzQ9M-BMqsig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "pqf1NpGHqvc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_data_loaders(traindata_dir, testdata_dir, batch_size=32, num_workers=0, valid_size=0.1):\n",
        "    image_transforms = {\n",
        "        # Train uses data augmentation\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "            transforms.RandomRotation(degrees=15),\n",
        "            transforms.ColorJitter(),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.CenterCrop(size=224),  # ImageNet standards\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet standards\n",
        "        ]),\n",
        "        # Test does not use augmentation\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize(size=256),\n",
        "            transforms.CenterCrop(size=224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    }\n",
        "\n",
        "    # Define datasets\n",
        "    dataset = {\n",
        "        'train': datasets.ImageFolder(root=traindata_dir, transform=image_transforms['train']),\n",
        "        'test': datasets.ImageFolder(root=testdata_dir, transform=image_transforms['test'])\n",
        "    }\n",
        "\n",
        "    # Splitting dataset into training and validation\n",
        "    num_test = len(dataset['train'])\n",
        "    indices = list(range(num_test))\n",
        "    split = int(np.floor(valid_size * num_test))\n",
        "\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    # Define dataloaders\n",
        "    dataloaders = {\n",
        "        'train': DataLoader(dataset['train'], batch_size=batch_size,sampler=train_sampler, num_workers=num_workers),\n",
        "        'test': DataLoader(dataset['test'], batch_size=batch_size,shuffle=True, num_workers=num_workers),\n",
        "        'val': DataLoader(dataset['train'], batch_size=batch_size,sampler=valid_sampler, num_workers=num_workers)\n",
        "    }\n",
        "\n",
        "    return dataloaders['train'], dataloaders['val'], dataloaders['test']\n"
      ],
      "metadata": {
        "id": "fnzEOs11qx05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZxR7kzsq25E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Initialize the EfficientNet-B2 model with pre-trained weights\n",
        "model = models.efficientnet_b1(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Determine the number of layers in the model\n",
        "num_layers = len(list(model.children()))\n",
        "\n",
        "# Specify the number of layers to freeze (initial convolutional layers)\n",
        "freeze_layers = 0\n",
        "\n",
        "# Freeze the initial convolutional layers\n",
        "for i, (name, param) in enumerate(model.named_parameters()):\n",
        "    if 'conv_stem' in name or i < freeze_layers:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Unfreeze the deeper layers\n",
        "for i, (name, param) in enumerate(model.named_parameters()):\n",
        "    if 'conv_stem' not in name and i >= freeze_layers:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Check which parameters are trainable\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.requires_grad)\n"
      ],
      "metadata": {
        "id": "HzLjLHpAq4pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n"
      ],
      "metadata": {
        "id": "tUL4eru_q_2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add on classifier\n",
        "model.classifier[1] = nn.Linear(1280, 200)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f'{total_params:,} total parameters.')\n",
        "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'{total_trainable_params:,} training parameters.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR47kIKurC7z",
        "outputId": "b2f5f383-df93-43f9-d329-eb6f9722ef0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6,769,384 total parameters.\n",
            "6,769,384 training parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/CUB_200_2011/train'\n",
        "test_dir = '/content/CUB_200_2011/test'\n",
        "\n",
        "train_loader, val_loader,test_loader = get_data_loaders(train_dir,test_dir)"
      ],
      "metadata": {
        "id": "Bl8eWlRC_Gxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Initialize model and move to device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.0001,weight_decay=1e-5)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 20\n",
        "training_loss_list = []\n",
        "validation_accuracy_list = []\n",
        "training_accuracy_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    training_loss_list.append(average_loss)\n",
        "    training_accuracy = 100 * correct_train / total_train\n",
        "    training_accuracy_list.append(training_accuracy)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100*accuracy_score(all_labels, all_preds)\n",
        "    validation_accuracy_list.append(accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {average_loss:.4f}, Train Accuracy: {training_accuracy:.2f}%, validation Accuracy: {accuracy:.4f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nudFHIwLrPDw",
        "outputId": "10e10563-1b72-4dc2-bbee-c662b509ad68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Average Training Loss: 5.0447, Train Accuracy: 5.99%, validation Accuracy: 18.6978%\n",
            "Epoch 2/20, Average Training Loss: 3.7722, Train Accuracy: 32.34%, validation Accuracy: 37.5626%\n",
            "Epoch 3/20, Average Training Loss: 2.5870, Train Accuracy: 52.97%, validation Accuracy: 51.5860%\n",
            "Epoch 4/20, Average Training Loss: 1.8352, Train Accuracy: 66.25%, validation Accuracy: 58.2638%\n",
            "Epoch 5/20, Average Training Loss: 1.3632, Train Accuracy: 74.96%, validation Accuracy: 65.4424%\n",
            "Epoch 6/20, Average Training Loss: 1.0273, Train Accuracy: 80.93%, validation Accuracy: 68.6144%\n",
            "Epoch 7/20, Average Training Loss: 0.7857, Train Accuracy: 84.99%, validation Accuracy: 71.6194%\n",
            "Epoch 8/20, Average Training Loss: 0.6310, Train Accuracy: 88.71%, validation Accuracy: 73.4558%\n",
            "Epoch 9/20, Average Training Loss: 0.5104, Train Accuracy: 90.38%, validation Accuracy: 74.4574%\n",
            "Epoch 10/20, Average Training Loss: 0.3968, Train Accuracy: 93.59%, validation Accuracy: 74.1235%\n",
            "Epoch 11/20, Average Training Loss: 0.3264, Train Accuracy: 95.03%, validation Accuracy: 74.7913%\n",
            "Epoch 12/20, Average Training Loss: 0.2557, Train Accuracy: 96.11%, validation Accuracy: 73.9566%\n",
            "Epoch 13/20, Average Training Loss: 0.2193, Train Accuracy: 96.70%, validation Accuracy: 74.2905%\n",
            "Epoch 14/20, Average Training Loss: 0.1778, Train Accuracy: 97.55%, validation Accuracy: 73.7896%\n",
            "Epoch 15/20, Average Training Loss: 0.1528, Train Accuracy: 98.16%, validation Accuracy: 74.2905%\n",
            "Epoch 16/20, Average Training Loss: 0.1270, Train Accuracy: 98.50%, validation Accuracy: 75.4591%\n",
            "Epoch 17/20, Average Training Loss: 0.1121, Train Accuracy: 98.59%, validation Accuracy: 76.6277%\n",
            "Epoch 18/20, Average Training Loss: 0.0927, Train Accuracy: 98.78%, validation Accuracy: 75.4591%\n",
            "Epoch 19/20, Average Training Loss: 0.0774, Train Accuracy: 99.26%, validation Accuracy: 75.2922%\n",
            "Epoch 20/20, Average Training Loss: 0.0718, Train Accuracy: 99.07%, validation Accuracy: 77.9633%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Test Accuracy: {100 * correct / total}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usEqkCdgAefI",
        "outputId": "48a515b6-7b17-4c8a-ad17-a9bbb4a911b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.47980669658267%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training Accuracy List: {training_accuracy_list}')\n",
        "print(f'Validation Accuracy List: {validation_accuracy_list}')\n",
        "print(f'Training Loss List: {training_loss_list}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OY8E_ZCKKFn",
        "outputId": "b5a4b2cb-f9b6-4888-ee9b-aa922df2051e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy List: [15.98264931598265, 44.07741074407741, 61.378044711378045, 71.25458792125458, 78.41174507841174, 83.667000333667, 86.48648648648648, 89.72305638972306, 92.75942609275943, 93.7771104437771, 95.42876209542877, 96.3963963963964, 96.91358024691358, 97.83116449783117, 98.54854854854855, 98.84884884884885, 98.98231564898232, 98.81548214881548, 99.18251584918252, 99.33266599933266]\n",
            "Validation Accuracy List: [37.99654576856649, 57.167530224525045, 67.18480138169257, 72.19343696027633, 76.16580310880829, 75.82037996545769, 78.23834196891191, 77.54749568221071, 78.23834196891191, 79.96545768566494, 80.31088082901555, 81.00172711571675, 80.31088082901555, 79.96545768566494, 80.82901554404145, 79.96545768566494, 81.51986183074266, 80.13816925734024, 80.82901554404145, 80.31088082901555]\n",
            "Training Loss List: [4.558079941475645, 3.085178770917527, 2.110614814656846, 1.5181881626869769, 1.1324887133025108, 0.8556809365115268, 0.6810854961897465, 0.5386697537404426, 0.4118055029118315, 0.34535892228496834, 0.27743108974809344, 0.22389506675461504, 0.1943276973956443, 0.16201654811726607, 0.12793075051554975, 0.10252553501978834, 0.0901398053293691, 0.08311826085790675, 0.07622649649435535, 0.05912900744798653]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save( model.state_dict(), \"/content/CUB_200_2011/Model_State_ENB1.pth\")"
      ],
      "metadata": {
        "id": "I_YuUWLaEKiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "import torch.nn as nn\n",
        "\n",
        "# Initialize EfficientNet B1\n",
        "model_b1 = models.efficientnet_b1(weights='IMAGENET1K_V1')\n",
        "\n",
        "\n",
        "# Assume the feature extraction part of B1 matches B0 and can accept the weights\n",
        "# Modify the classifier layer as per your requirement\n",
        "model_b1.classifier[1] = nn.Linear(1280, 200)\n",
        "\n",
        "total_params = sum(p.numel() for p in model_b1.parameters())\n",
        "print(f'{total_params:,} total parameters.')\n",
        "total_trainable_params = sum(p.numel() for p in model_b1.parameters() if p.requires_grad)\n",
        "print(f'{total_trainable_params:,} training parameters.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78_628ZPWq6c",
        "outputId": "8c851199-1ed2-4f41-8180-771d6b8aa470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b1\n",
            "6,769,384 total parameters.\n",
            "6,769,384 training parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_weights_path = '/content/CUB_200_2011/Model_State_ENB1.pth'\n",
        "\n",
        "# Load the state_dict of the B0 model\n",
        "b0_state_dict = torch.load(model_weights_path)\n",
        "\n",
        "# Load with strict=False to ignore incompatible keys\n",
        "model_b1.load_state_dict(b0_state_dict, strict=False)\n"
      ],
      "metadata": {
        "id": "eBL1-rA2YoIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming test_loader is already defined\n",
        "model_b1.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_b1.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_b1(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy of EfficientNet B1: {accuracy}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmo17cufYsXM",
        "outputId": "41da5e6b-3dc3-4ba7-9c80-35ecc2d502d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of EfficientNet B1: 0.25888850535036245%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming CUB-200-2011 has 200 classes\n",
        "num_classes = 200\n",
        "batch_size = 32\n",
        "num_epochs = 20\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Image transformations\n",
        "image_transforms = {\n",
        "    # Train uses data augmentation\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=299, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=30),\n",
        "        transforms.RandomRotation(degrees=45),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=299),  # Image net standards\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
        "    ]),\n",
        "\n",
        "    'test':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=299),\n",
        "        transforms.CenterCrop(size=299),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "# Datasets from folders\n",
        "data = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(root='/content/CUB_200_2011/train', transform=image_transforms['train']),\n",
        "    'test':\n",
        "    datasets.ImageFolder(root='/content/CUB_200_2011/test', transform=image_transforms['test']),\n",
        "}\n",
        "\n",
        "# Dataloader iterators, make sure to shuffle\n",
        "\n",
        "train_loader = DataLoader(data['train'], batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(data['test'], batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tx4sbvzXau4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.efficientnet_b1(weights='IMAGENET1K_V1')\n",
        "model.classifier[1] = nn.Linear(1280, 200)\n",
        "\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f'{total_params:,} total parameters.')\n",
        "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'{total_trainable_params:,} training parameters.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S_qnJsFa3Pm",
        "outputId": "5e5feffa-fe50-4583-d846-355ace48eca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6,769,384 total parameters.\n",
            "6,769,384 training parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
        "\n",
        "# Training the model\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.2f}%')\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Test Accuracy: {100 * correct / total}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfT3NiXfcE6W",
        "outputId": "4b9da848-1364-43ee-8e09-1852db892601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 4.5666, Train Accuracy: 14.06%\n",
            "Epoch [2/20], Loss: 3.1952, Train Accuracy: 35.39%\n",
            "Epoch [3/20], Loss: 2.2661, Train Accuracy: 55.69%\n",
            "Epoch [4/20], Loss: 1.6936, Train Accuracy: 66.97%\n",
            "Epoch [5/20], Loss: 1.2945, Train Accuracy: 74.42%\n",
            "Epoch [6/20], Loss: 1.0241, Train Accuracy: 79.13%\n",
            "Epoch [7/20], Loss: 0.8330, Train Accuracy: 82.23%\n",
            "Epoch [8/20], Loss: 0.6746, Train Accuracy: 85.57%\n",
            "Epoch [9/20], Loss: 0.5782, Train Accuracy: 87.35%\n",
            "Epoch [10/20], Loss: 0.4823, Train Accuracy: 90.41%\n",
            "Epoch [11/20], Loss: 0.4148, Train Accuracy: 91.27%\n",
            "Epoch [12/20], Loss: 0.3481, Train Accuracy: 92.79%\n",
            "Epoch [13/20], Loss: 0.3007, Train Accuracy: 93.74%\n",
            "Epoch [14/20], Loss: 0.2545, Train Accuracy: 95.15%\n",
            "Epoch [15/20], Loss: 0.2132, Train Accuracy: 96.26%\n",
            "Epoch [16/20], Loss: 0.1916, Train Accuracy: 96.38%\n",
            "Epoch [17/20], Loss: 0.1753, Train Accuracy: 96.98%\n",
            "Epoch [18/20], Loss: 0.1429, Train Accuracy: 97.33%\n",
            "Epoch [19/20], Loss: 0.1243, Train Accuracy: 97.83%\n",
            "Epoch [20/20], Loss: 0.1222, Train Accuracy: 97.58%\n",
            "Finished Training\n",
            "Test Accuracy: 81.32550914739386%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save( model.state_dict(), \"/content/CUB_200_2011/Model_State_ENB2.pth\")"
      ],
      "metadata": {
        "id": "HcFkte7AiziD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize EfficientNet B1\n",
        "model_b1 = models.efficientnet_b1(weights='IMAGENET1K_V1')\n",
        "\n",
        "\n",
        "# Assume the feature extraction part of B1 matches B0 and can accept the weights\n",
        "# Modify the classifier layer as per your requirement\n",
        "model_b1.classifier[1] = nn.Linear(1280, 200)\n",
        "\n",
        "total_params = sum(p.numel() for p in model_b1.parameters())\n",
        "print(f'{total_params:,} total parameters.')\n",
        "total_trainable_params = sum(p.numel() for p in model_b1.parameters() if p.requires_grad)\n",
        "print(f'{total_trainable_params:,} training parameters.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URwJWl4veREq",
        "outputId": "1fb1717b-3dc6-4960-a9e7-076f454cea18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6,769,384 total parameters.\n",
            "6,769,384 training parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_weights_path = '/content/CUB_200_2011/Model_State_ENB2.pth'\n",
        "\n",
        "# Load the state_dict of the B0 model\n",
        "b0_state_dict = torch.load(model_weights_path)\n",
        "\n",
        "# Load with strict=False to ignore incompatible keys\n",
        "model_b1.load_state_dict(b0_state_dict, strict=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8cWN6F2iF5J",
        "outputId": "4396298f-738f-4d2a-b081-ff6c42c11967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming test_loader is already defined\n",
        "model_b1.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_b1.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_b1(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy of EfficientNet B1: {accuracy}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOySjIcSiMCM",
        "outputId": "6dd37172-ec9e-452e-f123-c5a69f2e8730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of EfficientNet B1: 81.32550914739386%\n"
          ]
        }
      ]
    }
  ]
}